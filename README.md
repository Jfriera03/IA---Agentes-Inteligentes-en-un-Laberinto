# ğŸ” Agentes Inteligentes en un Laberinto

## ğŸ¤ Colaboradores

- [Jfriera03](https://github.com/Jfriera03)
- [MasoalM](https://github.com/MasoalM)

## ğŸ“Œ DescripciÃ³n

Este proyecto implementa agentes inteligentes que resuelven un laberinto mediante algoritmos de bÃºsqueda. Se desarrollan estrategias como DFS, A*, y Minimax con poda alfa-beta para optimizar el recorrido.

## ğŸ› ï¸ TecnologÃ­as y Herramientas

- **Lenguaje:** Python ğŸ
- **LibrerÃ­as utilizadas:** `heapq`, `math`, `random`, `pygame`.
- **Estructuras de datos empleadas:**
  - Diccionarios para el estado del entorno.
  - Pilas para la bÃºsqueda en profundidad.
  - Colas de prioridad para A*.
  - Ãrboles de decisiÃ³n para MiniMax.

## ğŸ“Œ Arquitectura del CÃ³digo

El cÃ³digo estÃ¡ estructurado en los siguientes archivos:

- **`__main__.py`**: Punto de entrada del programa, inicializa el entorno y ejecuta la simulaciÃ³n.
- **`agent.py`**: ImplementaciÃ³n bÃ¡sica de un agente.
- **`agent_profunditat.py`**: ImplementaciÃ³n del agente con bÃºsqueda en profundidad (DFS).
- **`agent_A_estrella.py`**: ImplementaciÃ³n del agente con el algoritmo A*.
- **`agent_MiniMaxAlfaBeta.py`**: ImplementaciÃ³n del agente con MiniMax y poda alfa-beta.
- **`estat.py`** y **`estatMiniMax.py`**: DefiniciÃ³n de estados y funciones auxiliares para la simulaciÃ³n.
- **`joc.py`**: Define el tablero y las reglas del juego.

## ğŸš€ InstalaciÃ³n y Uso

1. Clona el repositorio:
   ```bash
   git clone https://github.com/Jfriera03/agentes-laberinto.git
   ```
2. Accede al directorio del proyecto:
   ```bash
   cd agentes-laberinto
   ```
3. Instala las dependencias necesarias:
   ```bash
   pip install -r requirements.txt
   ```
4. Ejecuta el cÃ³digo principal:
   ```bash
   python __main__.py
   ```

## ğŸ® Funcionamiento del Algoritmo

El entorno es un tablero de tamaÃ±o configurable donde los agentes deben alcanzar su destino. Las acciones disponibles son:

- **Moverse** en las direcciones Norte, Sur, Este y Oeste.
- **Botar** sobre una casilla a dos distancias en cualquier direcciÃ³n.
- **Colocar una pared** para bloquear el paso del oponente.

Los agentes implementan diferentes estrategias para decidir su prÃ³ximo movimiento:

### ğŸ”¹ BÃºsqueda en Profundidad (DFS)
- Utiliza una **pila** para explorar caminos.
- No garantiza la soluciÃ³n mÃ¡s Ã³ptima.

### ğŸ”¹ Algoritmo A*
- Usa una **cola de prioridad** con heurÃ­stica basada en distancia Manhattan.
- Encuentra la soluciÃ³n Ã³ptima si la heurÃ­stica es admisible.

### ğŸ”¹ MiniMax con Poda Alfa-Beta
- Simula la estrategia de dos agentes compitiendo.
- Usa un **Ã¡rbol de decisiÃ³n** con profundidad limitada.
- Aplica **poda alfa-beta** para mejorar eficiencia.

## ğŸ—ï¸ ImplementaciÃ³n TÃ©cnica

### ğŸ“Œ Estados y PercepciÃ³n
Cada agente recibe informaciÃ³n sobre el entorno en forma de diccionario:
- **`PARETS`**: Lista de coordenadas donde hay paredes.
- **`TAULELL`**: Matriz que representa el tablero.
- **`DESTI`**: Coordenadas del objetivo.
- **`AGENTS`**: Diccionario con la posiciÃ³n de cada agente.

### ğŸ“Œ Clases Principales

- **`Viatger`** (Clase Base): Implementa la estructura bÃ¡sica del agente.
- **`Laberint`**: Controla la dinÃ¡mica del tablero y gestiona movimientos.
- **`EstatRobot` y `EstatMinimax`**: Modelan los estados y transiciones de los agentes.

### ğŸ“Œ Costes de Acciones
Las acciones tienen diferentes costos:
- **Moverse**: 1 unidad.
- **Botar**: 2 unidades.
- **Colocar una pared**: 4 unidades.

Los algoritmos consideran estos costos para optimizar sus decisiones.
